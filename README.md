SUMMARY

The primary challenge in interpreting Ground Penetrating Radar (GPR) data lies in its strong dependence on operator expertise, the lengthy analysis time, and the potential subjectivity of the results. To address these limitations, this study implements computer vision techniques using the YOLOv12 (You Only Look Once) model, which is capable of automatically detecting hyperbolic patterns commonly associated with subsurface utilities. A web-based application named “ITERA-VISION-GPR-UI (ITERA Vision System for GPR Utilities Inference)” was developed to perform object detection on GPR radargram images for subsurface utility identification. The dataset used in this research consists of 82 radargram images that underwent pre-processing and labelling using Roboflow. Model training was conducted on Google Colaboratory using the YOLOv12s variant with key parameters including 500 epochs, the AdamW optimizer, an input image size of 640 pixels (640 × 640 × 3), batch size of 1, and a patience value of 100. Model performance was evaluated using four main metrics: Precision, Recall, Mean Average Precision at an IoU threshold of 0.50 (mAP50), and Mean Average Precision across multiple IoU thresholds from 0.50 to 0.95 (mAP50-95). At epoch 292, the model achieved a Precision of 0.85, Recall of 0.77, mAP50 of 0.82, and mAP50-95 of 0.51, with an overall accuracy of 0.69. These results indicate that the model demonstrates satisfactory performance in detecting subsurface utilities. Despite certain limitations, the developed application has the potential to assist geophysicists in interpreting radargram images more efficiently, rapidly, and accurately.
Keywords: GPR; ITERA-VISION-GPR-UI; Computer vision; YOLOv12; Utilities.
